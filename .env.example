# Agent System Configuration
# Copy this file to .env and fill in your API keys

# =============================================================================
# API KEYS
# =============================================================================
# At least one API key is required for LLM functionality

# OpenAI API Key (for GPT models, embeddings)
OPENAI_API_KEY=your-openai-api-key-here

# Google API Key (for Gemini models)
GOOGLE_API_KEY=your-google-api-key-here

# Anthropic API Key (for Claude models)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
# Configure which models to use for each agent
# Available models:
#   OpenAI: gpt-4o, o3, o4-mini, o1-pro
#   Google: gemini-2.0-flash, gemini-2.5-pro, gemini-2.5-flash
#   Anthropic: claude-opus-4, claude-sonnet-4
# Aliases: fast, balanced, powerful, budget, premium, reasoning

# Agent-specific model configuration
# Default: All agents use gemini-2.5-flash
# Uncomment and modify to override specific agents:
# ARCHITECT_MODEL=gpt-4o           # Architect agent model
# REQUEST_PLANNER_MODEL=gpt-4o     # Request planner model
# CODING_MODEL=claude-sonnet-4     # Coding agent model
# ANALYZER_MODEL=gemini-2.0-flash  # Analyzer agent model
# GENERAL_MODEL=gpt-4o            # Default model for other uses

# Model aliases for quick selection
# ARCHITECT_MODEL=balanced       # Uses gpt-4o
# CODING_MODEL=powerful         # Uses claude-opus-4
# ANALYZER_MODEL=fast          # Uses gemini-2.0-flash

# =============================================================================
# AGENT SETTINGS
# =============================================================================
# Temperature and token limits can be configured per agent

# Temperature settings (0.0-2.0 for OpenAI/Google, 0.0-1.0 for Anthropic)
AGENT_LLM_TEMPERATURE=0.7

# Token limits
AGENT_LLM_MAX_TOKENS=4000

# Request timeout and retries
AGENT_LLM_REQUEST_TIMEOUT_SECONDS=30
AGENT_LLM_MAX_RETRIES=3
AGENT_LLM_RETRY_DELAY_SECONDS=1.0
AGENT_LLM_RETRY_BACKOFF_FACTOR=2.0

# =============================================================================
# SYSTEM CONFIGURATION
# =============================================================================

# Logging
AGENT_LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR
AGENT_LOG_FORMAT=structured  # text, structured, json
AGENT_LOG_DIR=logs
AGENT_LOG_FILE_NAME=agent.log

# Debug mode
AGENT_DEBUG=false

# =============================================================================
# RAG (Retrieval-Augmented Generation) CONFIGURATION
# =============================================================================

# Vector store settings
AGENT_RAG_VECTOR_STORE_TYPE=qdrant  # qdrant, chroma
AGENT_RAG_QDRANT_URL=http://localhost:6333
AGENT_RAG_QDRANT_COLLECTION=code_chunks

# Embedding settings
AGENT_RAG_EMBEDDING_MODEL=text-embedding-3-small
AGENT_RAG_EMBEDDING_BATCH_SIZE=100

# Chunking settings
AGENT_RAG_CHUNK_SIZE=1000
AGENT_RAG_CHUNK_OVERLAP=200

# Adaptive RAG settings
USE_ADAPTIVE_RAG=true
ADAPTIVE_RATE=0.1  # How quickly thresholds adapt (0.0-1.0)
OUTLIER_METHOD=mad  # Options: mad (default), iqr, zscore
MIN_CONTEXT_QUALITY=0.7  # Minimum acceptable context quality
MAX_BLINDSPOTS=3  # Maximum acceptable blindspots
TARGET_CHUNKS_PER_RETRIEVAL=5  # Target number of chunks

# =============================================================================
# WEBHOOK CONFIGURATION
# =============================================================================

# Webhook server
AGENT_WEBHOOK_ENABLED=false
AGENT_WEBHOOK_HOST=0.0.0.0
AGENT_WEBHOOK_PORT=8088

# Webhook authentication
AGENT_WEBHOOK_AUTH_ENABLED=true
AGENT_WEBHOOK_AUTH_TOKENS=["your-webhook-token"]
AGENT_WEBHOOK_SECRET_KEY=your-webhook-secret

# Rate limiting
AGENT_WEBHOOK_RATE_LIMIT_ENABLED=true
AGENT_WEBHOOK_RATE_LIMIT_REQUESTS=100
AGENT_WEBHOOK_RATE_LIMIT_WINDOW_SECONDS=60

# =============================================================================
# MESSAGING CONFIGURATION
# =============================================================================

# Messaging backend
AGENT_MESSAGING_BACKEND=memory  # memory, kafka, redis

# Kafka settings (if using Kafka)
AGENT_MESSAGING_KAFKA_BOOTSTRAP_SERVERS=localhost:9092
AGENT_MESSAGING_KAFKA_TOPIC_PREFIX=agent

# Queue settings
AGENT_MESSAGING_MAX_QUEUE_SIZE=1000
AGENT_MESSAGING_CONSUMER_TIMEOUT_MS=1000

# =============================================================================
# CACHE CONFIGURATION
# =============================================================================

# Cache backend
AGENT_CACHE_BACKEND=memory  # memory, redis
AGENT_CACHE_REDIS_URL=redis://localhost:6379
AGENT_CACHE_REDIS_DB=0

# Cache limits
AGENT_CACHE_TTL_SECONDS=3600
AGENT_CACHE_MAX_MEMORY_CACHE_ITEMS=10000
AGENT_CACHE_MAX_MEMORY_CACHE_MB=1024

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# Path security
AGENT_SECURITY_ENABLE_SYMLINK_CHECKS=true
AGENT_SECURITY_SANDBOX_GIT_OPERATIONS=true

# File patterns to exclude
AGENT_SECURITY_FORBIDDEN_PATTERNS=[".env", "*.key", "*.pem"]
AGENT_SECURITY_EXCLUDED_DIRS=[".git", "__pycache__", "node_modules"]

# =============================================================================
# COST TRACKING
# =============================================================================
# Cost tracking is automatically enabled when using the model card system
# View costs with: agent cost-summary

# Cost limits (optional)
# AGENT_MAX_COST_PER_SESSION=10.00  # USD
# AGENT_MAX_COST_PER_DAY=100.00     # USD